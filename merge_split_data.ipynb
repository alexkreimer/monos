{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle, numpy as np, glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_arrays(num_samples, num_features):\n",
    "  if num_samples:\n",
    "    X = np.ndarray((num_samples, num_features), dtype=np.float32)\n",
    "    y = np.ndarray(num_samples, dtype=np.float32)\n",
    "  else:\n",
    "    X, y = None, None\n",
    "  return X, y\n",
    "\n",
    "def merge_datasets(pickle_files):\n",
    "    num_parts = len(pickle_files)\n",
    "\n",
    "    X = None\n",
    "    y = None\n",
    "    for label, pickle_file in enumerate(pickle_files):       \n",
    "        try:\n",
    "            with open(pickle_file, 'rb') as f:\n",
    "                sequence_data = pickle.load(f)\n",
    "        except Exception as e:\n",
    "          print('Unable to process data from', pickle_file, ':', e)\n",
    "          raise\n",
    "\n",
    "        if X is not None:\n",
    "            X = np.vstack((X, sequence_data['X']))\n",
    "            y = np.hstack((y, sequence_data['y']))\n",
    "            \n",
    "        else:\n",
    "            X = sequence_data['X']\n",
    "            y = sequence_data['y']\n",
    "    \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X (69537, 88) y (69537,)\n",
      "48675 10432 10432\n",
      "X (69537, 1592) y (69537,)\n",
      "48675 10432 10432\n"
     ]
    }
   ],
   "source": [
    "def shuffle_in_unison(X, y):\n",
    "    assert len(X) == len(y)\n",
    "    p = np.random.permutation(len(X))\n",
    "    return X[p,:], y[p]\n",
    "\n",
    "def split_data(X, y, train_size, valid_size, test_size):\n",
    "    train_X, train_y = X[:train_size,:], y[:train_size]\n",
    "    k = train_size + valid_size\n",
    "    valid_X, valid_y = X[train_size:k,:], y[train_size:k]\n",
    "    test_X, test_y = X[k:(k+test_size),:], y[k:(k+test_size)]\n",
    "    \n",
    "    return train_X, train_y, valid_X, valid_y, test_X, test_y\n",
    "\n",
    "for label in ['5bins_edges', '200bins']:\n",
    "    files = glob.glob('data/*_%s.pickle' % label)\n",
    "    X, y = merge_datasets(files)\n",
    "    X, y = shuffle_in_unison(X,y)\n",
    "    print('X', X.shape, 'y', y.shape)\n",
    "    pickle.dump({'X': X, 'y': y}, open('data/dataset_%s.pickle' % label, 'wb'))\n",
    "\n",
    "    size = len(X)\n",
    "    train_size = int(.7*size)\n",
    "    valid_size = int(.15*size)\n",
    "    test_size = size-train_size-valid_size\n",
    "\n",
    "    train_X, train_y, valid_X, valid_y, test_X, test_y = split_data(X, y, train_size, valid_size, test_size)\n",
    "    print(len(train_X), len(test_X), len(test_y))\n",
    "    pickle.dump({'X': train_X, 'y': train_y}, open('data/train_%s.pickle' % label, 'wb'))\n",
    "    pickle.dump({'X': valid_X, 'y': valid_y}, open('data/valid_%s.pickle' % label, 'wb'))\n",
    "    pickle.dump({'X': test_X, 'y': test_y}, open('data/test_%s.pickle' % label, 'wb'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
