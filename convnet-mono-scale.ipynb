{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage before: 1133.98046875 MiB\n",
      "Memory usage after reading the images: 1134.1875 MiB\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "from numpy import linalg as LA\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = (20.0, 10.0)\n",
    "import pandas as pd\n",
    "\n",
    "seq = '00'\n",
    "KITTI_HOME = '/home/kreimer/KITTI'\n",
    "seq_dir = os.path.join(KITTI_HOME, 'dataset', 'sequences', seq)\n",
    "image_0 = os.path.join(seq_dir, 'image_0')\n",
    "calib_file = os.path.join(KITTI_HOME, 'dataset', 'sequences', seq, 'calib.txt')\n",
    "\n",
    "with open(calib_file, 'r') as f:\n",
    "    for line in f:\n",
    "        line = [float(v) for v in line.split()[1:] ]\n",
    "        K = np.array(line).reshape(3,4)\n",
    "        break\n",
    "\n",
    "Intrinsic = namedtuple('intrinsic', ['f', 'pp'])\n",
    "intr = Intrinsic(f = K[0,0], pp=K[range(2),2])\n",
    "\n",
    "def read_scales(file):\n",
    "    scales = []\n",
    "    with open(file, 'r') as f:\n",
    "        for line in f:\n",
    "            pose = np.array([float(val) for val in line.split()]).reshape(3,4)\n",
    "            pose = np.vstack((pose, [0, 0, 0, 1]))\n",
    "            try:\n",
    "                delta = np.dot(LA.inv(ppose), pose)\n",
    "            except NameError:\n",
    "                ppose = pose\n",
    "                continue\n",
    "\n",
    "            scale = LA.norm(delta[:3,3])\n",
    "            scales.append(scale)\n",
    "\n",
    "            ppose = pose\n",
    "    return scales\n",
    "\n",
    "def read_image(path, mask, i):\n",
    "    file_path = os.path.join(path, mask % i)\n",
    "    pil_image = Image.open(file_path).convert('RGB') \n",
    "    cv_image = np.array(pil_image) \n",
    "    cv_image = cv_image[:, :, ::-1].copy()\n",
    "    gray = cv2.cvtColor(cv_image, cv2.COLOR_BGR2GRAY)\n",
    "    return gray\n",
    "\n",
    "def memory_usage_psutil():\n",
    "    # return the memory usage in MB\n",
    "    import psutil\n",
    "    process = psutil.Process(os.getpid())\n",
    "    mem = process.memory_info()[0] / float(2 ** 20)\n",
    "    return mem\n",
    "\n",
    "scales = read_scales('data/%s.txt' % seq)\n",
    "scales = np.array(scales)\n",
    "\n",
    "print('Memory usage before:', memory_usage_psutil(), 'MiB')\n",
    "\n",
    "sequences = ['00', '01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11']\n",
    "seq = '04'\n",
    "\n",
    "scales = read_scales('data/%s.txt' % seq)\n",
    "scales = np.array(scales)\n",
    "num_frames = scales.shape[0]\n",
    "\n",
    "data = np.zeros([268, 376*2, 1241, 1], dtype=np.float32)\n",
    "for i in range(num_frames):\n",
    "    image = read_image(image_0, '%06d.png', i+1)\n",
    "    if i<num_frames-1:\n",
    "        data[i,:376,:,0] = image\n",
    "    if i>0:\n",
    "        data[i-1,376:,:,0] = image\n",
    "\n",
    "print('Memory usage after reading the images:', memory_usage_psutil(), 'MiB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scales size:  (269,)\n",
      "images size:  (268, 752, 1241, 1) dtype float32\n",
      "image height 752 image width 1241\n"
     ]
    }
   ],
   "source": [
    "print('scales size: ', scales.shape)\n",
    "print('images size: ', data.shape, 'dtype', data.dtype)\n",
    "\n",
    "image_height, image_width = data.shape[1:3]\n",
    "print('image height', image_height, 'image width', image_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 376, 1241, 1)\n",
      "Tensor(\"Conv2D:0\", shape=(16, 376, 1241, 16), dtype=float32)\n",
      "Tensor(\"concat:0\", shape=(16, 3735936), dtype=float32)\n",
      "Initialized\n",
      "(269,)\n",
      "(269,)\n",
      "(269,)\n",
      "(269,)\n",
      "(269,)\n",
      "(269,)\n",
      "(269,)\n",
      "(269,)\n",
      "(269,)\n",
      "(269,)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-81094e23bdfe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mtrain_data\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m     \u001b[1;31m#if (step % 50 == 0):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[1;31m#  print('Minibatch loss at step %d: %f' % (step, l))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kreimer/prj/monos/.env/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    338\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 340\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    341\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kreimer/prj/monos/.env/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    562\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m       results = self._do_run(handle, target_list, unique_fetches,\n\u001b[1;32m--> 564\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    565\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m       \u001b[1;31m# The movers are no longer used. Delete them.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kreimer/prj/monos/.env/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    635\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m--> 637\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m    638\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    639\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m/home/kreimer/prj/monos/.env/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m    642\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 644\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    645\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStatusNotOK\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    646\u001b[0m       \u001b[0merror_message\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_message\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kreimer/prj/monos/.env/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m    626\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m         return tf_session.TF_Run(\n\u001b[1;32m--> 628\u001b[1;33m             session, None, feed_dict, fetch_list, target_list, None)\n\u001b[0m\u001b[0;32m    629\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    630\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range\n",
    "\n",
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])\n",
    "\n",
    "batch_size = 16\n",
    "depth = 16 # the number of output feature maps\n",
    "num_hidden = 64\n",
    "num_labels = 1\n",
    "num_channels = 1\n",
    "kernel_size = 5\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "  # Input data.\n",
    "  train_data = tf.placeholder(tf.float32, shape=(batch_size, image_height, image_width, num_channels))\n",
    "  y = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "\n",
    "  # Variables.\n",
    "  weights1a = tf.Variable(tf.truncated_normal([kernel_size, kernel_size, num_channels, depth], stddev=0.1))\n",
    "  biases1a = tf.Variable(tf.zeros([depth]))\n",
    "\n",
    "  weights2 = tf.Variable(tf.truncated_normal([batch_size, image_height//4, image_width//2, depth], stddev=0.1))\n",
    "  #biases2 = tf.Variable(tf.constant(1.0, shape=[image_width*image_height//2]))\n",
    "  \n",
    "  # Model.\n",
    "  def model(batch):\n",
    "    images1, images2 = batch[:,:376,:,0], batch[:,376:,:,0]\n",
    "\n",
    "    images1 = tf.reshape(images1, [16, 376, 1241, 1])\n",
    "    images2 = tf.reshape(images2, [16, 376, 1241, 1])\n",
    "    \n",
    "    # convolutional layers that share weights: siamese architecture of LeCun.\n",
    "    print(images1.get_shape())\n",
    "    conv1a = tf.nn.conv2d(images1, weights1a, [1,1,1,1], padding='SAME')\n",
    "    print(conv1a)\n",
    "    hidden1a = tf.nn.relu(conv1a + biases1a)\n",
    "    h_pool1a = tf.nn.max_pool(hidden1a, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "\n",
    "    conv1b = tf.nn.conv2d(images2, weights1a, [1,1,1,1], padding='SAME')\n",
    "    hidden1b = tf.nn.relu(conv1b + biases1a)\n",
    "    h_pool1b = tf.nn.max_pool(hidden1b, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "\n",
    "    reshape1a = tf.reshape(h_pool1a, [batch_size, -1])\n",
    "    reshape1b = tf.reshape(h_pool1b, [batch_size, -1])\n",
    "    \n",
    "    dim = reshape1a.get_shape()[1].value\n",
    "    weights = tf.Variable(tf.truncated_normal([2*dim, 1], stddev=0.1))\n",
    "    biases = tf.Variable(tf.constant(0.1, shape=[1]))\n",
    "\n",
    "    flat = tf.concat(1, [reshape1a, reshape1b])\n",
    "    print(flat)\n",
    "    local1 = tf.nn.relu(tf.matmul(flat, weights) + biases)\n",
    "\n",
    "    return local1\n",
    "  \n",
    "  # Training computation.\n",
    "  y_ = model(train_data)\n",
    "  loss = tf.reduce_sum(tf.square(y_ - y))\n",
    " \n",
    "  # Optimizer.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.05).minimize(loss)\n",
    "\n",
    "num_steps = 10\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.initialize_all_variables().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    print(scales.shape)\n",
    "    offset = (step * batch_size) % (scales.shape[0] - batch_size)\n",
    "    \n",
    "    batch_data = data[offset:(offset + batch_size), :, :, :]\n",
    "    batch_labels = np.reshape(scales[offset:(offset + batch_size)], [batch_size, 1])\n",
    "    \n",
    "    feed_dict = {train_data : batch_data, y : batch_labels}\n",
    "    \n",
    "    session.run([optimizer, loss], feed_dict=feed_dict)\n",
    "    if (step % 50 == 0):\n",
    "      print('Minibatch loss at step %d: %f' % (step, loss))\n",
    "      print('Minibatch accuracy: %.1f%%' % accuracy(predictions, batch_labels))\n",
    "      print('Validation accuracy: %.1f%%' % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "  print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
